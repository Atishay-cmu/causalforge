{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d588506",
   "metadata": {},
   "source": [
    "# Loading Real-World & Benchmarking Datasets with CausalForge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b3ae",
   "metadata": {},
   "source": [
    "A dataset used for causal studies is, in general, different from datasets used for associational studies. \n",
    "In causal inference we have a fundamental problem which is, indeed, referred as fundamental problem of causal inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a70c89",
   "metadata": {},
   "source": [
    "__Fundamental problem of causal inference (FPCI)__: _we do not observe both potential outcomes (control & treated), but \n",
    "    we only observe one._ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc0931",
   "metadata": {},
   "source": [
    "Indeed, this formulation of FPCI holds only for binary exposures, when we have two cohorts: \n",
    "    treated & control (or untreated). In case of T exposures, we observe only one potential outcome and we do not \n",
    "    observe the remaining T-1. An unobserved potential outcome is generally referred as \n",
    "    __counterfactual__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4c15f",
   "metadata": {},
   "source": [
    "In causal inference we have \n",
    "\n",
    "* __real-world datasets__: these datasets are real datasets; they are typically observational and obey to the FPCI, hence, they don't come with \n",
    "    counterfactuals; as a conseguence, it should not be possible to do causal model validation on this kind of daatsets, \n",
    "    although they are people who adopt associational metrics (e.g. accuracy or auROC)\n",
    "    pretending they are proxies of causal metrics like PEHE (Precision in Estimation of Heterogeneous Effect) \n",
    "    or ATE (Average Treatment Effect) MAE (Mean Absolute Error), which, on the contrary, \n",
    "    requires counterfactuals for computation; \n",
    "    \n",
    "* __benchmarking datasets__: these datasets can be either simulations or combinations of real-world datasets and \n",
    "    RCTs, and __they come with counterfactuals__; they can be used to do causal model validation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc48faf",
   "metadata": {},
   "source": [
    "With CausalForge it is very easy to load a dataset. First, you want to load a proper __data loader__ given the name \n",
    "of the dataset, and then you want to load all the typical ingredients of a causal inference \n",
    "dataset, i.e., __covariates__, __teatment assigments__, __factuals__ and, if available, __counterfactuals__.\n",
    "\n",
    "Let's see this in action with a dataset very popular in the causal inference community: __IHDP__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fe13b",
   "metadata": {},
   "source": [
    "## The IHDP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b1121",
   "metadata": {},
   "source": [
    "The Infant Health and Development Program (IHDP) is a randomized controlled study designed to evaluate the effect of home visit from specialist doctors on the cognitive test scores of premature infants. The datasets is first used for benchmarking treatment effect estimation algorithms in Hill [1], where selection bias is induced by removing non-random subsets of the treated individuals to create an observational dataset, and the outcomes are generated using the original covariates and treatments. It contains 747 subjects and 25 variables. In order to compare our results with the literature and make our results reproducible, we use the simulated outcome implemented as setting “A” in [2], and downloaded the data at https://www.fredjo.com/, which is composed of 1000 repetitions of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7091682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 19:05:37.783274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((672, 25, 1000),\n",
       " (672, 1000),\n",
       " (672, 1000),\n",
       " (672, 1000),\n",
       " (672, 1000),\n",
       " (672, 1000))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalforge.data_loader import DataLoader \n",
    "\n",
    "r = DataLoader.get_loader('IHDP').load()\n",
    "X_tr, T_tr, YF_tr, YCF_tr, mu_0_tr, mu_1_tr, X_te, T_te, YF_te, YCF_te, mu_0_te, mu_1_te = r \n",
    "\n",
    "X_tr.shape, T_tr.shape, YF_tr.shape, YCF_tr.shape, mu_0_tr.shape , mu_1_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687e3aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75, 25, 1000), (75, 1000), (75, 1000), (75, 1000), (75, 1000), (75, 1000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te.shape, T_te.shape, YF_te.shape , YCF_te.shape, mu_0_te.shape , mu_1_te.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfab197",
   "metadata": {},
   "source": [
    "Specifically, \n",
    "\n",
    "* __for the trainset__ X_tr, T_tr, YF_tr, YCF_tr, mu_0_tr, mu_1_tr  are covariates, treatment, factual outcome, counterfactual outcome, and noiseless potential outcomes respectively; \n",
    "* __for the testset__ X_te, T_te, YF_te, YCF_te, mu_0_te, mu_1_te  are covariates, treatment, factual outcome, counterfactual outcome, and noiseless potential outcomes respectively; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8df14",
   "metadata": {},
   "source": [
    "Notice that the last dimension of each variable is 1000, as we have 1000 repetitions of the experiment.\n",
    "Hence, this dataset should be used pretty much like in this code sketch:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++ Experiment  0 / 1000\n",
      "  ATE (train/test):: 4.0144505901891705 4.0305489972436686\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  1 / 1000\n",
      "  ATE (train/test):: 4.061018726235442 3.9596262629599708\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  2 / 1000\n",
      "  ATE (train/test):: 4.110469801399948 3.9978605132504823\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  3 / 1000\n",
      "  ATE (train/test):: 4.254634722808619 4.4443103197221285\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  4 / 1000\n",
      "  ATE (train/test):: 4.151266973614955 4.262547405163926\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  5 / 1000\n",
      "  ATE (train/test):: 4.011426976855247 3.937131526610354\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  6 / 1000\n",
      "  ATE (train/test):: 3.9941264781108985 3.958499708600623\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  7 / 1000\n",
      "  ATE (train/test):: 3.869525188323851 3.7114417347352258\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  8 / 1000\n",
      "  ATE (train/test):: 10.202749856423566 12.825092953893234\n",
      "  ITE (train/test):: (672,) (75,)\n",
      "++++ Experiment  9 / 1000\n",
      "  ATE (train/test):: 4.787728196307775 2.7785207988543785\n",
      "  ITE (train/test):: (672,) (75,)\n"
     ]
    }
   ],
   "source": [
    "for idx in range(X_tr.shape[-1]):    \n",
    "    t_tr, y_tr, x_tr, mu0tr, mu1tr = T_tr[:,idx] , YF_tr[:,idx], X_tr[:,:,idx], mu_0_tr[:,idx], mu_1_tr[:,idx] \n",
    "    t_te, y_te, x_te, mu0te, mu1te = T_te[:,idx] , YF_te[:,idx], X_te[:,:,idx], mu_0_te[:,idx], mu_1_te[:,idx]  \n",
    "\n",
    "    # Train your causal method on train-set ...\n",
    "\n",
    "    # Validate your method test-set ... \n",
    "    ATE_truth_tr = (mu1tr - mu0tr).mean()\n",
    "    ATE_truth_te = (mu1te - mu0te).mean()\n",
    "    \n",
    "    ITE_truth_tr = (mu1tr - mu0tr)\n",
    "    ITE_truth_te = (mu1te - mu0te)\n",
    "    \n",
    "    if idx<10:\n",
    "        print(\"++++ Experiment \",idx,\"/\",X_tr.shape[-1])\n",
    "        print(\"  ATE (train/test)::\", ATE_truth_tr, ATE_truth_te)\n",
    "        print(\"  ITE (train/test)::\", ITE_truth_tr.shape, ITE_truth_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e47fb",
   "metadata": {},
   "source": [
    "Whatever metric is adopted, at the end, results should be averaged over the 1000 repetitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d37e54",
   "metadata": {},
   "source": [
    "Notice that even if we use the ground truth on the train-set to estimate the ATE of the test-set \n",
    "we don't have a zero error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a2fbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5879717298086842"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalforge.metrics import eps_ATE\n",
    "import numpy as np\n",
    "\n",
    "eps_ATE(np.vstack([mu1tr,mu0tr]).transpose() , np.vstack([mu1te,mu0te]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5e4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f2ab15",
   "metadata": {},
   "source": [
    "## References "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98863e",
   "metadata": {},
   "source": [
    "1. [Hill J.L., Bayesian nonparametric modeling for causal inference, J. Comput. Graph. Statist., 20 (1) (2011), pp. 217-240, 10.1198/jcgs.2010.08162](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162)\n",
    "\n",
    "2. Shi C., Blei D.M., Veitch V., Adapting neural networks for the estimation of treatment effects Wallach H.M., Larochelle H., Beygelzimer A., d’Alché Buc F., Fox E.B., Garnett R. (Eds.), NeurIPS (2019), pp. 2503-2513"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalforge",
   "language": "python",
   "name": "causalforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
